{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal;\">CIS 211 Project 2:  Cryptography</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Due 11:00 P.M. January 20, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading:  M&R 3.1 -- 3.3, 3.5; &nbsp; 8.1 -- 8.2, 8.4.1 -- 8.4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week we're going to use simple encryption and decryption algorithms as a way of exploing strings and containers (lists, dictionaries, and sets) in Python.\n",
    "\n",
    "Encryption is described in Chapter 3 of the textbook.  You should understand how the **substitution cipher** works -- you don't need to understand the details of any of the Python functions that implement the method, but you should know what it means to encode a piece of text with this kind of cipher.\n",
    "\n",
    "Decrypting a piece of text (assuming it really was encrypted with a substitution cipher) is not too hard, compared to other forms of encryption, but still more than we want to do in a one-week project.  Instead of developing an algorithm that will decrypt a piece of text we'll write a few small \"helper functions\" that might be useful as part of a larger application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:teal\">Part 1: &nbsp; Word Lists (25 points)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several steps in a decrytion algorithm need to see if a string is a valid English word.  We need a Python data structure that allows for a fast lookup in a collection of 100,000 or more strings.  \n",
    "\n",
    "We could store the words in a list, but (as you should recall from CIS 210) the amount of time to find a string in a list is proportional to the length of the list.\n",
    "\n",
    "In Chapter 8 there is a suggestion to use a dictionary instead of a list.  Each key is an English word and the value can be anything, *e.g.* the number 0:\n",
    "\n",
    "``` \n",
    "words = { 'a' : 0, 'aardvark' : 0, 'abaci' : 0, ... }\n",
    "```\n",
    "\n",
    "To see if a string is an English word just check to see if the string is a key, using the `in` operator:\n",
    "```\n",
    "if w in words:\n",
    "   ...\n",
    "```\n",
    "The time for this operation is proportional to $log_2 n$ where $n$ is the number of words in the dictionary.\n",
    "\n",
    "What about sets?  Do you think Python organizes set objects so it can do a $log_2$ time lookup?  This project will help you find out.\n",
    "\n",
    "**The `wordlist_sample` Function**\n",
    "\n",
    "Write a function named `wordlist_sample` that has two arguments, `n` and `all_types`.  If `all_types` is `False` just return a list of `n` words chosen at random from the English dictionary.  If `all_types` is `True` return three containers, a list, a dictionary, and a set, each containing the same words.\n",
    "\n",
    "Examples:\n",
    "<pre>\n",
    ">>> wl = wordlist_sample(5)\n",
    ">>> print(wl)\n",
    "['felicitating', 'submergible', 'duarchies', 'inglorious', 'phonophore']\n",
    "\n",
    ">>> wl, wd, ws = wordlist_sample(5, True)\n",
    ">>> print(wl); print(wd); print(ws)\n",
    "['chronometry', 'vicariousness', 'mischarged', 'gadding', 'languishing']\n",
    "{'languishing': 0, 'vicariousness': 0, 'gadding': 0, 'chronometry': 0, 'mischarged': 0}\n",
    "{'gadding', 'languishing', 'vicariousness', 'chronometry', 'mischarged'}\n",
    "</pre>\n",
    "\n",
    "**Note:** &nbsp; The first line of the function has been written for you.  It will make a list of all words in a file named `wordlist.txt` (which is available on Canvas).  You just need to fill in the rest of the function.\n",
    "\n",
    "**Style Points**\n",
    "\n",
    "See if you can use a constructor to make each container instead of iterating over the list of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Code</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3bd78942509e6d6268aa6ae2c9a9833f",
     "grade": true,
     "grade_id": "wordlists",
     "locked": false,
     "points": 8,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def wordlist_sample(size, all_types=False):\n",
    "    '''\n",
    "    Make a random sample words from the wordlist file.  Return them as\n",
    "    a list if all_types is False, otherwise return them in a list, \n",
    "    dictionary, and set (to allow experiments on the same sample but\n",
    "    with different data structures).\n",
    "    '''\n",
    "\n",
    "    all_words = list(map(str.strip, open('wordlist.txt').readlines()))\n",
    "\n",
    "    samp_list = random.sample(all_words, size)\n",
    "    samp_dict = dict.fromkeys(samp_list, '0')\n",
    "    if all_types == False:\n",
    "        return samp_list\n",
    "    else:\n",
    "        return samp_list, samp_dict, set(samp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Autograder Tests</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "56466ec97f5456e2ab6d4bbad39a7152",
     "grade": true,
     "grade_id": "struct_test_1",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Make a list of 10 words, verify the result is a list of 10 strings\n",
    "\n",
    "wl = wordlist_sample(10)\n",
    "assert len(wl) == 10\n",
    "assert isinstance(wl, list)\n",
    "for x in wl:\n",
    "    assert isinstance(x,str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c7fdde1973a0ff1ef0115b22175e3df7",
     "grade": true,
     "grade_id": "struct_test_2",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Make three containers, verify the second is a dictionary and that \n",
    "# all words in the list are also in the dictionary\n",
    "\n",
    "wl, wd, ws = wordlist_sample(10, True)\n",
    "assert len(wd) == 10\n",
    "assert isinstance(wd, dict)\n",
    "for x in wl:\n",
    "    assert x in wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "187c9127c8795601364c9dd0e24c6ed6",
     "grade": true,
     "grade_id": "struct_test_3",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Same as above, but verify the third container is a set\n",
    "\n",
    "wl, wd, ws = wordlist_sample(10, True)\n",
    "assert len(ws) == 10\n",
    "assert isinstance(ws, set)\n",
    "for x in wl:\n",
    "    assert x in ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Documentation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c5833941ce2be5ab556fd659398718a2",
     "grade": true,
     "grade_id": "wordlist_doc",
     "locked": false,
     "points": 5,
     "solution": true
    }
   },
   "source": [
    "random.sample is exactly what we need to use for this so we pass it with the given variables\n",
    "made a dictionary with dict.fromkeys from the sample list from the prior line, give it keys of '0' for placeholders\n",
    "now the if statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:teal\">Part 2: &nbsp; Looking Up Words (10 points)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the body of the function named `lookup_words` below.  The arguments are `words`, which will be a random list of words, and `struct`, which you can assume is one of the three containers produced by a call to your `wordlist_sample` function.\n",
    "\n",
    "The function should iterate over the word list to look up each word in `struct`.  Conveniently for us, the Python code that searches for a word in a container is the same for all three container types:  the expression `x in struct` is `True` if `x` is in a list, or `x` is a key in a dictionary, or `x` is a member of a set.\n",
    "\n",
    "Your function should return the number of items from your list of random words that were found in `struct`.\n",
    "\n",
    "**No Documentation**\n",
    "\n",
    "Since this is such a simple function you don't need to write any documentation for it.  Just fill in the code cell and run the autograder tests to make sure it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Code</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6faad06967e53b96fc5e7f7a70ac71cc",
     "grade": true,
     "grade_id": "lookup_words",
     "locked": false,
     "points": 5,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def lookup_words(words, struct):\n",
    "    '''\n",
    "    Return the number of strings in words that are found in struct\n",
    "    '''\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word in struct:\n",
    "            count += 1\n",
    "    return count\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Autograder Tests</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e5d09dd40564a2563d6128b343a8bb4c",
     "grade": true,
     "grade_id": "lookup_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This test makes sure the lookup_words function works for all three container types.\n",
    "# The list used in the test is a set of nonsense words that are not in the dictionary.\n",
    "\n",
    "gibberish = ['bryllyg', 'slythy', 'toves', 'mimsy', 'borogroves']\n",
    "\n",
    "wl, wd, ws = wordlist_sample(10, all_types=True)\n",
    "\n",
    "assert lookup_words(gibberish, wl) == 0\n",
    "assert lookup_words(gibberish, wd) == 0\n",
    "assert lookup_words(gibberish, ws) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:teal\">Part 3: Experiments (30 points)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the project you are going to run some experiments to measure how long it takes to look up words in each type of container.\n",
    "\n",
    "To help with the experiments we have defined a special type of class called a \"context manager\" and a helper function named `time_lookups` that uses the context manager to measure execution time.  All you have to do is call the helper function, passing it a list of words and one of your container classes, and the function will return the number of milliseconds the system took to look up all the words.\n",
    "\n",
    "Execute this code cell to define the context manager and helper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    '''\n",
    "    A Timer object is a context manager that can be used to measure execution times.\n",
    "    '''\n",
    "    def __enter__(self):\n",
    "        self._start = time.time()\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        self._stop = time.time()\n",
    "        self.msecs = 1000 * (self._stop - self._start)\n",
    "        \n",
    "def time_lookups(lst, struct, n = 10):\n",
    "    '''\n",
    "    Return the amount of time it takes to look up all the strings in lst\n",
    "    in a container (a set, dictionary, or list).  The return value is the\n",
    "    average execution time measured over n tests.\n",
    "    '''\n",
    "    tsum = 0\n",
    "    with Timer() as t:\n",
    "        for i in range(n):\n",
    "            lookup_words(lst, struct)\n",
    "    return t.msecs / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below shows how to use `time_lookups` to measure how long it takes to search for the nonsense words a list of size 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  0.0\n"
     ]
    }
   ],
   "source": [
    "wl = wordlist_sample(10)\n",
    "print('t = ', time_lookups(['bryllyg', 'slythy', 'toves', 'mimsy', 'borogroves'], wl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows it took my computer about 0.0018 milliseconds (or 1.8 μsec) to do the searches (if you execute the code cell your computer will probably have a different timing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the body of the function named `run_experiment` in the code cell below.  When the function is called it should make three containers (list, dictionary, and set) of the specified size, and then it should call `time_lookups` to measure the amount of time it takes to search for nonsense words in each container.\n",
    "\n",
    "Some details:\n",
    "* you can make up your own list of words to search, or use the \"gibberish\" words from previous examples\n",
    "* you can decide how to report the results, _e.g._ the function can return a list of three time values, or it can print the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Code</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0b165b463beed2cc73a39661297f7902",
     "grade": true,
     "grade_id": "run_experiment",
     "locked": false,
     "points": 10,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  0.0\n",
      "t =  0.0\n",
      "t =  0.0\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(size):\n",
    "    wl, wd, ws = wordlist_sample(size, all_types=True)\n",
    "    short = ['bryllyg', 'slythy', 'toves', 'mimsy', 'borogroves']\n",
    "    print('t = ', time_lookups(short, wl, size))\n",
    "    print('t = ', time_lookups(short, wd, size))\n",
    "    print('t = ', time_lookups(short, ws ,size))\n",
    "run_experiment(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Results</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no requirement for documentation for your `run_experiments` function.  \n",
    "\n",
    "Instead, you should run several experiments, with containers of different sizes, so you can see how the size of a container has an effect on the time it takes to search through it.\n",
    "Use the markdown cell below to summarize the results.\n",
    "* does the time required to search a list grow linearly with the number of items in the list?\n",
    "* are execution times for sets and dictionaries lower than for lists with the same number of items?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d8648d7d2e7b59f00ffea38a69947937",
     "grade": true,
     "grade_id": "results",
     "locked": false,
     "points": 20,
     "solution": true
    }
   },
   "source": [
    "ran with a sample of 10, 100, 1000 with no large difference.\n",
    "sample of 10000 words has a noticable time difference between lists and sets/dictionaries, lists being slower\n",
    "sample of 10000 words also show that dictionaries are slightly faster than sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:teal\">Part 4: Organizing Words by Size (35 points)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful data structure for a program that decrypts a piece of text is a collection of words that is organized by word length.  At times we'd like to have a list of all 2-letter words, 3-letter words, and so on.\n",
    "\n",
    "We could build such a list using all the words in the dictionary, but another strategy would be to use words that are more commonly used.\n",
    "\n",
    "For this part of the project, fill in the body of the function below.  The function is passed the name of a text file.  You should split the text into individual words, and save each word in the container that holds all words of that length.  Since we don't want duplicates, a set is the natural choice for this container.  Return a dictionary that maps a word length to the set of all words of that length.\n",
    "\n",
    "Here is an example, using a short quotation as in the input text.  The file named `quote.txt` contains this quotation:\n",
    "> If you have no confidence in self,\n",
    ">   you are twice defeated in the race of life.\n",
    "> With confidence, you have won even before you have started.\n",
    ">    -- Marcus Tullius Cicero (106 BC -- 43 BC)\n",
    "\n",
    "Your function should return this output:\n",
    "```\n",
    ">>> words_by_length('quote.txt')\n",
    "{2: {'43', 'bc', 'if', 'in', 'no', 'of'},\n",
    " 3: {'106', 'are', 'the', 'won', 'you'},\n",
    " 4: {'even', 'have', 'life', 'race', 'self', 'with'},\n",
    " 5: {'twice'},\n",
    " 6: {'before', 'cicero', 'marcus'},\n",
    " 7: {'started', 'tullius'},\n",
    " 8: {'defeated'},\n",
    " 10: {'confidence'}}\n",
    "```\n",
    "\n",
    "Note how punctuation has been stripped away from the ends of words, and that all words are converted to lower case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Code</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4f8252119bdddfa7fdb936037f2be53b",
     "grade": true,
     "grade_id": "wordlength",
     "locked": false,
     "points": 15,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def words_by_length(filename):\n",
    "    file = open(filename, 'r')\n",
    "    words = set(file.read().split())\n",
    "    nd = {}\n",
    "    file.close()\n",
    "    for word in words:\n",
    "        ref = ''\n",
    "        for ch in word:\n",
    "            if ch not in set(punctuation):\n",
    "                ref += ch\n",
    "        if (ref != 0) and (len(ref) != 0):\n",
    "            if len(ref.lower()) not in nd.keys():\n",
    "                nd.update({len(ref): [ref.lower()]})\n",
    "            else: \n",
    "                nd[len(ref)].append(ref.lower())\n",
    "    return nd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Autograder Tests</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e526703182f22569ad5e46272cf8db8f",
     "grade": true,
     "grade_id": "length_test_1",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dct = words_by_length('quote.txt')\n",
    "assert isinstance(dct, dict)\n",
    "assert len(dct) == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f84167e24fef03daafbdd5a99ad9e6ad",
     "grade": true,
     "grade_id": "length_test_2",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-c4d180a5e3ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords_by_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'quote.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32massert\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'even'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'have'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'life'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'race'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'self'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'with'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;32massert\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'twice'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dct = words_by_length('quote.txt')\n",
    "assert dct[4] == {'even', 'have', 'life', 'race', 'self', 'with'}\n",
    "assert dct[5] == {'twice'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:red\">Documentation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "577da5972c06b475854bf815c9599bbb",
     "grade": true,
     "grade_id": "wordlength_doc",
     "locked": false,
     "points": 10,
     "solution": true
    }
   },
   "source": [
    "So I open the file, and turn its contents into a set, close it.\n",
    "i iterate through every value of the set, taking the set i extract the text from the punctuation and put it in a dictionary value and with the key as the length.\n",
    "if the length is in the dictionary we just add the word to the list of values for the respective key\n",
    "\n",
    "\n",
    "I've never had more trouble with one singular thing in my entire life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:teal\">Extra Credit Ideas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 8.4 of the textbook describes various techniques for breaking a substitution cipher.  Here are some ideas for extra credit for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a string containing one of my favorite quotes, encrypted with a substitution cipher. It should be pretty easy to decrypt using the techniques from the book.  Decrypt this quote and e-mail the plaintext to `cis211-extra@cs.uoregon.edu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quote = '''\n",
    "DYGJTAL DV P ADR, P EDDX TJ P CPZ'J ELJG VWTLZA. \n",
    "TZJTAL DV P ADR TG'J GDD APWX GD WLPA.\n",
    "  -- RWDYIMD CPWH\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substitute English Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function named `apply` that will see what happens when letters from a ciphertext word are replaced by English words in a piece of text.  The first argument should be a set of upper case letters in the quote, the second should be a string of the same length, containing lower case letters, and the third is the complete ciphertext.\n",
    "\n",
    "For example, if you guess `ELJG` is the code for `fish` you can see what would happen if that guess is applied to the entire text:\n",
    "```\n",
    ">>> print(apply('ELJG', 'fish', quote))\n",
    "DYhsTAi DV P ADR, P fDDX Ts P CPZ's fish VWTiZA. \n",
    "TZsTAi DV P ADR Th's hDD APWX hD WiPA.\n",
    "  -- RWDYIMD CPWH\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c18752ec1888f957671d9a0b02b15bbd",
     "grade": false,
     "grade_id": "apply",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply(cipher, plain, text):\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
